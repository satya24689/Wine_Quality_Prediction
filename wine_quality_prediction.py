# -*- coding: utf-8 -*-
"""Wine Quality Prediction

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yxdA7InhGKil1JdoMHkRP0X3DNzQWPjk

IMPORTING LIBRARIES
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns


from warnings import filterwarnings
filterwarnings(action='ignore')

"""LOADING DATASET"""

wine = pd.read_csv("winequality-red.csv")
wine.sample(25)

wine.info()

"""DESCRIPTION"""

wine.describe()

"""FINDING NULL VALUES"""

wine.isnull().sum()

wine.groupby('quality').mean()

"""DATA ANALYSIS

COUNTPLOT:
"""

sns.countplot(wine['quality'])
plt.show()

wine.plot(kind ='box',subplots = True, layout =(4,4),sharex = False)

wine['fixed acidity'].plot(kind ='box')

"""Histogram"""

wine.hist(figsize=(10,10),bins=50)
plt.show()

"""Feature Selection"""

wine.sample(5)

wine['quality'].unique()

# If wine quality is 7 or above then will consider as good quality wine
wine['goodquality'] = [1 if x >= 7 else 0 for x in wine['quality']]
wine.sample(5)

# See total number of good vs bad wines samples
wine['goodquality'].value_counts()

# Separate depedent and indepedent variables
X = wine.drop(['quality','goodquality'], axis = 1)
Y = wine['goodquality']

X

print(Y)

""" FEATURE  IMPORTANCE"""

from sklearn.ensemble import ExtraTreesClassifier
classifiern = ExtraTreesClassifier()
classifiern.fit(X,Y)
score = classifiern.feature_importances_
print(score)

"""SPLITTING DATASET"""

from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.3,random_state=7)

"""RESULT"""

model_res=pd.DataFrame(columns=['Model', 'Score'])

"""LOGISTIC REGRESSION"""

from sklearn.linear_model import LogisticRegression
model = LogisticRegression()
model.fit(X_train,Y_train)
y_pred = model.predict(X_test)

from sklearn.metrics import accuracy_score,confusion_matrix
# accuracy_score(Y_test,Y_pred)
model_res.loc[len(model_res)] = ['LogisticRegression', accuracy_score(Y_test,y_pred)]
model_res

"""USING  KNN"""

from sklearn.neighbors import KNeighborsClassifier
model = KNeighborsClassifier(n_neighbors=3)
model.fit(X_train,Y_train)
y_pred = model.predict(X_test)

from sklearn.metrics import accuracy_score
model_res.loc[len(model_res)] = ['KNeighborsClassifier', accuracy_score(Y_test,y_pred)]
model_res

"""USING SVC"""

from sklearn.svm import SVC
model = SVC()
model.fit(X_train,Y_train)
y_pred = model.predict(X_test)

from sklearn.metrics import accuracy_score
print("Accuracy Score:",accuracy_score(Y_test,y_pred))
model_res.loc[len(model_res)] = ['SVC', accuracy_score(Y_test,y_pred)]
model_res

"""Using Decision Tree"""

from sklearn.tree import DecisionTreeClassifier
model = DecisionTreeClassifier(criterion='entropy',random_state=7)
model.fit(X_train,Y_train)
y_pred = model.predict(X_test)

from sklearn.metrics import accuracy_score
print("Accuracy Score:",accuracy_score(Y_test,y_pred))
model_res.loc[len(model_res)] = ['DecisionTreeClassifier', accuracy_score(Y_test,y_pred)]
model_res

"""Using GaussianNB:"""

from sklearn.naive_bayes import GaussianNB
model3 = GaussianNB()
model3.fit(X_train,Y_train)
y_pred = model3.predict(X_test)

from sklearn.metrics import accuracy_score
print("Accuracy Score:",accuracy_score(Y_test,y_pred))
model_res.loc[len(model_res)] = ['GaussianNB', accuracy_score(Y_test,y_pred)]
model_res

"""Using Random Forest:"""

from sklearn.ensemble import RandomForestClassifier
model2 = RandomForestClassifier(random_state=1)
model2.fit(X_train, Y_train)
y_pred = model2.predict(X_test)

from sklearn.metrics import accuracy_score
print("Accuracy Score:",accuracy_score(Y_test,y_pred))
model_res.loc[len(model_res)] = ['RandomForestClassifier', accuracy_score(Y_test,y_pred)]
model_res

# !pip install xgboost

"""Usig Xgboost:"""

import xgboost as xgb
model5 = xgb.XGBClassifier(random_state=1)
model5.fit(X_train, Y_train)
y_pred = model5.predict(X_test)

from sklearn.metrics import accuracy_score
print("Accuracy Score:",accuracy_score(Y_test,y_pred))
model_res.loc[len(model_res)] = ['XGBClassifier', accuracy_score(Y_test,y_pred)]
model_res

model_res = model_res.sort_values(by='Score', ascending=False)
model_res